{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to download the collected works of Nietzsche to use as our data for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/nietzsche/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
    "text = open(f'{PATH}nietzsche.txt').read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 85\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "indices_char[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=3\n",
    "c1_dat = [idx[i]    for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c2_dat = [idx[i+1]    for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c3_dat = [idx[i+2]    for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c4_dat = [idx[i+3]    for i in range(0, len(idx) - 1 - cs, cs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40, 43])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200295,), (200295,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256 # number of hidden activations\n",
    "n_fac = 42     # embedding matrix size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        \n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        \n",
    "        # square weight matrix\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self,  c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1, x2, x3], axis=1), y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Char3Model(vocab_size, n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 67\n",
       "  9\n",
       " 74\n",
       "  1\n",
       " 67\n",
       " 54\n",
       " 78\n",
       "  2\n",
       " 74\n",
       "  2\n",
       " 28\n",
       " 54\n",
       " 69\n",
       "  2\n",
       "  1\n",
       " 66\n",
       "  2\n",
       " 67\n",
       "  2\n",
       " 67\n",
       "  8\n",
       " 68\n",
       " 71\n",
       "  2\n",
       " 58\n",
       "  2\n",
       "  2\n",
       " 65\n",
       " 72\n",
       " 71\n",
       " 73\n",
       " 62\n",
       " 58\n",
       " 10\n",
       " 72\n",
       " 68\n",
       " 60\n",
       "  2\n",
       " 65\n",
       " 54\n",
       "  2\n",
       " 78\n",
       " 73\n",
       " 67\n",
       " 63\n",
       " 58\n",
       " 72\n",
       " 72\n",
       " 71\n",
       "  1\n",
       "  2\n",
       " 74\n",
       " 58\n",
       "  8\n",
       " 54\n",
       " 76\n",
       " 58\n",
       " 62\n",
       " 65\n",
       " 73\n",
       " 67\n",
       " 31\n",
       " 54\n",
       "  2\n",
       " 62\n",
       " 67\n",
       " 73\n",
       " 57\n",
       " 71\n",
       "  9\n",
       " 58\n",
       " 61\n",
       " 56\n",
       " 73\n",
       " 68\n",
       " 76\n",
       " 72\n",
       " 71\n",
       " 58\n",
       " 71\n",
       " 76\n",
       " 72\n",
       " 71\n",
       " 68\n",
       "  2\n",
       " 46\n",
       " 72\n",
       " 62\n",
       " 65\n",
       " 68\n",
       " 58\n",
       " 78\n",
       " 69\n",
       " 67\n",
       " 61\n",
       " 58\n",
       " 74\n",
       "  2\n",
       " 61\n",
       " 54\n",
       " 67\n",
       " 72\n",
       " 62\n",
       " 58\n",
       " 74\n",
       " 10\n",
       " 10\n",
       " 58\n",
       " 62\n",
       " 58\n",
       "  2\n",
       " 72\n",
       " 56\n",
       " 60\n",
       " 73\n",
       " 61\n",
       " 10\n",
       " 61\n",
       " 67\n",
       "  2\n",
       " 68\n",
       " 73\n",
       " 71\n",
       " 44\n",
       " 58\n",
       "  2\n",
       " 78\n",
       " 62\n",
       "  2\n",
       " 64\n",
       " 73\n",
       " 60\n",
       " 56\n",
       " 71\n",
       "  2\n",
       " 59\n",
       " 44\n",
       "  9\n",
       " 78\n",
       " 61\n",
       "  2\n",
       "  2\n",
       "  2\n",
       "  2\n",
       " 55\n",
       " 62\n",
       " 58\n",
       " 54\n",
       " 73\n",
       "  2\n",
       " 54\n",
       " 58\n",
       "  1\n",
       "  8\n",
       " 68\n",
       "  2\n",
       " 62\n",
       "  2\n",
       " 78\n",
       " 72\n",
       " 56\n",
       " 68\n",
       " 78\n",
       " 57\n",
       " 68\n",
       " 66\n",
       "  2\n",
       " 58\n",
       " 54\n",
       " 69\n",
       " 77\n",
       " 10\n",
       " 58\n",
       "  8\n",
       " 62\n",
       " 73\n",
       " 61\n",
       " 67\n",
       " 68\n",
       " 58\n",
       " 71\n",
       " 58\n",
       "  2\n",
       " 56\n",
       " 72\n",
       " 73\n",
       "  1\n",
       " 57\n",
       "  2\n",
       " 56\n",
       " 73\n",
       " 59\n",
       " 58\n",
       " 74\n",
       "  2\n",
       " 55\n",
       " 68\n",
       "  2\n",
       " 67\n",
       " 73\n",
       " 68\n",
       " 54\n",
       " 55\n",
       " 29\n",
       "  2\n",
       " 73\n",
       " 58\n",
       " 57\n",
       " 62\n",
       " 45\n",
       " 68\n",
       " 68\n",
       " 56\n",
       " 59\n",
       " 73\n",
       " 67\n",
       " 65\n",
       " 72\n",
       " 62\n",
       " 72\n",
       " 67\n",
       " 54\n",
       " 69\n",
       " 58\n",
       " 58\n",
       " 66\n",
       " 58\n",
       "  1\n",
       "  2\n",
       " 59\n",
       " 78\n",
       " 62\n",
       " 59\n",
       " 69\n",
       " 69\n",
       " 57\n",
       " 62\n",
       " 58\n",
       "  2\n",
       " 72\n",
       " 68\n",
       " 54\n",
       "  8\n",
       " 59\n",
       " 56\n",
       " 72\n",
       " 59\n",
       "  2\n",
       " 67\n",
       " 67\n",
       " 73\n",
       "  9\n",
       "  2\n",
       " 58\n",
       "  2\n",
       "  2\n",
       " 58\n",
       "  2\n",
       " 69\n",
       " 71\n",
       " 68\n",
       "  2\n",
       " 73\n",
       " 55\n",
       " 72\n",
       " 68\n",
       " 58\n",
       " 36\n",
       "  2\n",
       " 60\n",
       " 60\n",
       " 59\n",
       "  2\n",
       " 58\n",
       " 59\n",
       "  1\n",
       " 62\n",
       " 58\n",
       "  2\n",
       " 72\n",
       " 59\n",
       "  2\n",
       " 43\n",
       "  2\n",
       "  8\n",
       " 76\n",
       " 54\n",
       " 75\n",
       " 54\n",
       "  2\n",
       " 62\n",
       "  1\n",
       " 65\n",
       " 62\n",
       " 62\n",
       " 54\n",
       " 62\n",
       " 62\n",
       " 68\n",
       " 71\n",
       " 68\n",
       " 73\n",
       " 62\n",
       " 67\n",
       "  8\n",
       " 72\n",
       "  2\n",
       " 65\n",
       " 68\n",
       " 57\n",
       " 78\n",
       " 68\n",
       " 58\n",
       " 66\n",
       " 78\n",
       " 59\n",
       " 58\n",
       " 43\n",
       " 54\n",
       " 68\n",
       " 54\n",
       " 72\n",
       " 54\n",
       " 58\n",
       " 73\n",
       " 58\n",
       "  2\n",
       "  2\n",
       " 71\n",
       " 57\n",
       " 71\n",
       " 61\n",
       " 61\n",
       " 73\n",
       " 74\n",
       " 72\n",
       " 72\n",
       " 73\n",
       " 78\n",
       " 67\n",
       "  2\n",
       " 54\n",
       " 72\n",
       " 73\n",
       " 78\n",
       "  1\n",
       " 71\n",
       " 73\n",
       "  2\n",
       " 61\n",
       " 57\n",
       " 61\n",
       " 71\n",
       "  2\n",
       " 54\n",
       " 59\n",
       " 73\n",
       " 58\n",
       " 61\n",
       "  2\n",
       " 58\n",
       " 56\n",
       "  2\n",
       "  2\n",
       " 76\n",
       "  2\n",
       " 58\n",
       " 54\n",
       " 73\n",
       " 63\n",
       " 78\n",
       "  8\n",
       " 59\n",
       " 43\n",
       " 62\n",
       " 72\n",
       "  2\n",
       " 58\n",
       " 58\n",
       " 73\n",
       " 67\n",
       " 73\n",
       " 72\n",
       "  2\n",
       " 65\n",
       " 73\n",
       " 72\n",
       " 58\n",
       " 62\n",
       " 67\n",
       "  2\n",
       " 56\n",
       " 74\n",
       " 58\n",
       " 78\n",
       "  2\n",
       "  2\n",
       " 10\n",
       " 43\n",
       " 73\n",
       " 57\n",
       " 68\n",
       " 67\n",
       " 58\n",
       " 73\n",
       "  9\n",
       " 62\n",
       " 68\n",
       " 67\n",
       "  2\n",
       "  2\n",
       " 57\n",
       " 76\n",
       " 57\n",
       " 61\n",
       " 67\n",
       " 58\n",
       " 68\n",
       " 68\n",
       " 61\n",
       " 55\n",
       " 54\n",
       "  9\n",
       " 73\n",
       " 30\n",
       " 62\n",
       " 59\n",
       "  2\n",
       " 68\n",
       " 74\n",
       " 73\n",
       " 62\n",
       " 55\n",
       "  2\n",
       " 62\n",
       " 69\n",
       " 71\n",
       " 78\n",
       "  2\n",
       " 74\n",
       " 57\n",
       " 57\n",
       " 72\n",
       "  6\n",
       "  2\n",
       " 57\n",
       " 71\n",
       " 45\n",
       " 72\n",
       " 67\n",
       " 68\n",
       " 71\n",
       " 68\n",
       " 62\n",
       " 10\n",
       " 61\n",
       " 71\n",
       " 57\n",
       " 65\n",
       " 73\n",
       " 65\n",
       " 67\n",
       " 54\n",
       " 73\n",
       " 73\n",
       " 72\n",
       " 58\n",
       " 72\n",
       " 68\n",
       " 58\n",
       " 61\n",
       " 71\n",
       " 54\n",
       " 72\n",
       " 73\n",
       "  2\n",
       " 78\n",
       " 71\n",
       " 60\n",
       " 68\n",
       " 66\n",
       " 73\n",
       " 62\n",
       " 67\n",
       " 61\n",
       " 62\n",
       " 72\n",
       " 72\n",
       " 61\n",
       "  8\n",
       " 73\n",
       " 71\n",
       " 61\n",
       " 78\n",
       " 68\n",
       " 71\n",
       " 54\n",
       " 62\n",
       " 68\n",
       "  2\n",
       " 24\n",
       " 73\n",
       " 58\n",
       " 73\n",
       " 68\n",
       " 61\n",
       " 71\n",
       " 67\n",
       " 73\n",
       " 58\n",
       " 74\n",
       " 56\n",
       "[torch.cuda.LongTensor of size 512 (GPU 0)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-4.3346 -4.5751 -4.5236  ...  -4.6200 -4.6187 -4.1334\n",
       "-4.3079 -4.5833 -4.4472  ...  -4.5442 -4.4554 -4.2949\n",
       "-4.4424 -4.5095 -4.3915  ...  -4.5107 -4.3939 -4.1684\n",
       "          ...             ⋱             ...          \n",
       "-4.3834 -4.7395 -4.4694  ...  -4.6188 -4.4127 -4.3297\n",
       "-4.2271 -4.2028 -4.5030  ...  -4.5055 -4.2388 -4.3235\n",
       "-4.3346 -4.5751 -4.5236  ...  -4.6200 -4.6187 -4.1334\n",
       "[torch.cuda.FloatTensor of size 512x85 (GPU 0)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692efa10f9444ad8b341e7b0d4440cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      2.098631   5.497483  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 5.49748])]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f286c1a2dc8e415993b84da2db5a5b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.854464   4.958208  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 4.95821])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 0.001)\n",
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]\n",
    "\n",
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i + j] for i in range(cs)] for j in range(len(idx)-cs-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(c_in_dat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600884, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600884,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
       "       [42, 29, 30, 25, 27, 29,  1,  1],\n",
       "       [29, 30, 25, 27, 29,  1,  1,  1],\n",
       "       [30, 25, 27, 29,  1,  1,  1, 43],\n",
       "       [25, 27, 29,  1,  1,  1, 43, 45],\n",
       "       [27, 29,  1,  1,  1, 43, 45, 40],\n",
       "       [29,  1,  1,  1, 43, 45, 40, 40],\n",
       "       [ 1,  1,  1, 43, 45, 40, 40, 39]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 43, 45, 40, 40, 39, 43])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(idx)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 480312 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-0328b88818c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColumnarModelData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/column_data.py\u001b[0m in \u001b[0;36mfrom_arrays\u001b[0;34m(cls, path, val_idxs, xs, y, is_reg, is_multi, bs, test_xs, shuffle)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_xs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_xs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPassthruDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_xs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_xs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_multi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtest_xs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         return cls(path, PassthruDataset(*(trn_xs.T), trn_y, is_reg=is_reg, is_multi=is_multi),\n",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/dataset.py\u001b[0m in \u001b[0;36msplit_by_idx\u001b[0;34m(idxs, *a)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \"\"\"\n\u001b[1;32m    605\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 480312 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "            \n",
    "        return F.log_softmax(self.l_out(h))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopModel(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00e1534a1a04af1bd82271a56cdc2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      2.022062   2.009667  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 2.00967])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7051a9b5c8d44e47a4abdc12c129f6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.732963   1.733791  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.73379])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = torch.cat((h, self.e(c)), 1)\n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = F.tanh(self.l_hidden(inp))\n",
    "            \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopConcatModel(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e4438ebe964684b6651346698d6dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      2.116697   5.206744  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 5.20674])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71d1ab9ac044877be05500fbce0c4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.995689   5.007091  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 5.00709])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('ello my ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('my name ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp, h = self.rnn(inp, h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 42])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512, n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 85])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs));\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bc13b285644d2b99999c9141f69900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      2.190345   3.843704  \n",
      "    1      1.968257   4.464006                              \n",
      "    2      1.86239    5.010817                               \n",
      "    3      1.796672   5.027993                               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 5.02799])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b7be2a32a5425ba75a7d0a1ce1159d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.753373   5.177734  \n",
      "    1      1.745874   5.28944                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 5.28944])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for thosenter and thereneran an an an an an an a'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
